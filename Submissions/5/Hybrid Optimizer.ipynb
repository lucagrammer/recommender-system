{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import FileManager\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from Recommenders.ScoresHybridRecommender import ScoresHybridRecommender\n",
    "from Recommenders.ScoresHybrid2Recommender import ScoresHybrid2Recommender\n",
    "from Recommenders.ScoresHybrid3Recommender import ScoresHybrid3Recommender\n",
    "from Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender\n",
    "from Recommenders.MatrixFactorization.PureSVDRecommender import PureSVDRecommender\n",
    "from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Importing file...\n",
      "> Importing file... Completed!\n",
      "> Importing file...\n",
      "> Importing file... Completed!\n"
     ]
    }
   ],
   "source": [
    "#ratings = FileManager.load_data()\n",
    "#users_to_recommend = np.array(FileManager.load_target()).squeeze()\n",
    "#urm_all,urm_train,urm_validation= FileManager.split_data(ratings)\n",
    "#urm_train_validation = urm_train + urm_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm_train=sp.load_npz(\"saved_urm/urm_train.npz\")\n",
    "urm_validation=sp.load_npz(\"saved_urm/urm_validation.npz\")\n",
    "urm_train_validation=sp.load_npz(\"saved_urm/urm_train_validation.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Ignoring 13646 ( 0.0%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "evaluator_validation = EvaluatorHoldout(urm_validation, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ TRAIN SLIM ################\n",
    "slimElasticNet= SLIMElasticNetRecommender(urm_train)\n",
    "slimElasticNet.fit(topK=707, l1_ratio=3.7848901259206446e-05, alpha=0.8041273931917446)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ SAVE SLIM ################\n",
    "slimElasticNet.save_model(folder_path='saved_models/train/',file_name='slimElasticNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: Loading model from file 'saved_models/train/SLIMElasticNet_best_latest'\n",
      "SLIMElasticNetRecommender: Loading complete\n"
     ]
    }
   ],
   "source": [
    "################ LOAD SLIM ################\n",
    "slimElasticNetLoaded= SLIMElasticNetRecommender(urm_train)\n",
    "slimElasticNetLoaded.load_model(folder_path='saved_models/train/',file_name='SLIMElasticNet_best_latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PURE SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureSVDRecommender: Computing SVD decomposition...\n",
      "PureSVDRecommender: Computing SVD decomposition... done in 3.55 sec\n"
     ]
    }
   ],
   "source": [
    "################ TRAIN PURE SVD ################\n",
    "pureSVD= PureSVDRecommender(urm_train)\n",
    "pureSVD.fit(num_factors=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureSVDRecommender: Saving model in file 'saved_models/train/pureSVD'\n",
      "PureSVDRecommender: Saving complete\n"
     ]
    }
   ],
   "source": [
    "################ SAVE  PURE SVD ################\n",
    "pureSVD.save_model(folder_path='saved_models/train/',file_name='pureSVD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureSVDRecommender: Loading model from file 'saved_models/train/pureSVD'\n",
      "PureSVDRecommender: Loading complete\n"
     ]
    }
   ],
   "source": [
    "################ LOAD PURE SVD ################\n",
    "pureSVDloaded= PureSVDRecommender(urm_train)\n",
    "pureSVDloaded.load_model(folder_path='saved_models/train/',file_name='pureSVD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 13650 (100.0%), 371.49 column/sec. Elapsed time 36.74 sec\n"
     ]
    }
   ],
   "source": [
    "################ TRAIN USER KNN ################\n",
    "userKNN=UserKNNCFRecommender(urm_train)\n",
    "userKNN.fit(topK=677, shrink=302, similarity='cosine', normalize=True, feature_weighting='TF-IDF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNNCFRecommender: Saving model in file 'saved_models/train/userKNNcf'\n",
      "UserKNNCFRecommender: Saving complete\n"
     ]
    }
   ],
   "source": [
    "################ SAVE  USER KNN ################\n",
    "userKNN.save_model(folder_path='saved_models/train/',file_name='userKNNcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNNCFRecommender: Loading model from file 'saved_models/train/UserKNNCF_best'\n",
      "UserKNNCFRecommender: Loading complete\n"
     ]
    }
   ],
   "source": [
    "################ LOAD USER KNN ################\n",
    "userKNNLoaded= UserKNNCFRecommender(urm_train)\n",
    "userKNNLoaded.load_model(folder_path='saved_models/train/',file_name='UserKNNCF_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HYBRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreshybridrecommender= ScoresHybridRecommender(urm_train,slimElasticNetLoaded,userKNNLoaded)\n",
    "#scoreshybridrecommender.fit(alpha=0.77535)\n",
    "#scoreshybridrecommender.fit(alpha=0.8109400848162426)\n",
    "scoreshybridrecommender.fit(alpha=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreshybrid2recommender= ScoresHybridRecommender(urm_train,slimElasticNetLoaded,pureSVD)\n",
    "scoreshybrid2recommender.fit(alpha=0.77535)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "import scipy.sparse as sps\n",
    "\n",
    "\n",
    "class ScoresHybridRecommender(BaseRecommender):\n",
    "    \"\"\" ScoresHybridRecommender\n",
    "    Hybrid of two prediction scores R = R1*alpha + R2*(1-alpha)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"ScoresHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2):\n",
    "        super(ScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "\n",
    "    def fit(self, alpha=0.5):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "\n",
    "        # In a simple extension this could be a loop over a list of pretrained recommender objects\n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array,items_to_compute)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array,items_to_compute)\n",
    "\n",
    "        item_weights = item_weights_1 * self.alpha + item_weights_2 * (1 - self.alpha)\n",
    "\n",
    "        return item_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 13646 (100.0%) in 47.83 sec. Users per second: 285\n",
      "cutoff\n",
      "10    0.245009\n",
      "Name: MAP, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_df, _ = evaluator_validation.evaluateRecommender(scoreshybrid2recommender)\n",
    "print(result_df['MAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 13646 (100.0%) in 53.41 sec. Users per second: 255\n",
      "cutoff\n",
      "10    0.243595\n",
      "Name: MAP, dtype: object\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 1.15 min. Users per second: 198\n",
      "cutoff\n",
      "10    0.244281\n",
      "Name: MAP, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for rec in [slimElasticNetLoaded,scoreshybridrecommender]:\n",
    "    result_df, _ = evaluator_validation.evaluateRecommender(rec)\n",
    "    print(result_df['MAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer, Categorical\n",
    "from HyperparameterTuning.SearchBayesianSkopt import SearchBayesianSkopt\n",
    "from HyperparameterTuning.SearchAbstractClass import SearchInputRecommenderArgs\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "import os\n",
    "\n",
    "\n",
    "hyperparameters_range_dictionary = {\n",
    "    \"alpha\": Real(low = 0.01, high = 1, prior = 'log-uniform'),\n",
    "}\n",
    "\n",
    "\n",
    "output_folder_path = \"Optimization_FINAL_HYBRID/\"\n",
    "\n",
    "# If directory does not exist, create\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "    \n",
    "n_cases = 60  # NUMBER OF CASES\n",
    "n_random_starts = int(n_cases*0.15)\n",
    "metric_to_optimize = \"MAP\"\n",
    "cutoff_to_optimize = 10\n",
    "\n",
    "\n",
    "recommender_input_args = SearchInputRecommenderArgs(\n",
    "    CONSTRUCTOR_POSITIONAL_ARGS = [urm_train,slimElasticNetLoaded,userKNNLoaded],     # For a CBF model simply put [URM_train, ICM_train]\n",
    "    CONSTRUCTOR_KEYWORD_ARGS = {},\n",
    "    FIT_POSITIONAL_ARGS = [],\n",
    "    FIT_KEYWORD_ARGS =  {}    # Additiona hyperparameters for the fit function\n",
    ")\n",
    "#recommender_input_args_last_test = SearchInputRecommenderArgs( CONSTRUCTOR_POSITIONAL_ARGS = [urm_train_validation,slimElasticNetLoaded,pureSVDloaded,userKNNLoaded],     # For a CBF model simply put [URM_train_validation, ICM_train] CONSTRUCTOR_KEYWORD_ARGS = {}, FIT_POSITIONAL_ARGS = [], FIT_KEYWORD_ARGS = {}   # Additiona hyperparameters for the fit function)\n",
    "\n",
    "recommender_class = ScoresHybridRecommender\n",
    "\n",
    "hyperparameterSearch = SearchBayesianSkopt(recommender_class,\n",
    "                                         evaluator_validation=evaluator_validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchBayesianSkopt: Extending previous number of cases from 60 to 65.\n",
      "\n",
      "SearchBayesianSkopt: Resuming 'ScoresHybridRecommender'... Loaded 60 configurations.\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "SearchBayesianSkopt: Search interrupted due to ValueError. The evaluated configurations may have had all the same value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN THE OPTIMIZER\n",
    "\n",
    "hyperparameterSearch.search(recommender_input_args,\n",
    "                       #recommender_input_args_last_test = recommender_input_args_last_test,\n",
    "                       hyperparameter_search_space = hyperparameters_range_dictionary,\n",
    "                       n_cases = n_cases,\n",
    "                       n_random_starts = n_random_starts,\n",
    "                       save_model = \"no\",\n",
    "                       resume_from_saved=True,\n",
    "                       output_folder_path = output_folder_path, # Where to save the results\n",
    "                       output_file_name_root = recommender_class.RECOMMENDER_NAME, # How to call the files\n",
    "                       metric_to_optimize = metric_to_optimize,\n",
    "                       cutoff_to_optimize = cutoff_to_optimize,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
